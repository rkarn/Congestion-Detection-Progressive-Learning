{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "\n",
    "# Read in the training CSV file\n",
    "print(\"Reading Training csv file.\")\n",
    "df1 = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "df1.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df=df1\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto\"].astype('category')\n",
    "obj_df[\"service\"] = obj_df[\"service\"].astype('category')\n",
    "obj_df[\"state\"] = obj_df[\"state\"].astype('category')\n",
    "obj_df[\"proto_cat\"] = obj_df[\"proto\"].cat.codes\n",
    "obj_df[\"service_cat\"] = obj_df[\"service\"].cat.codes\n",
    "obj_df[\"state_cat\"] = obj_df[\"state\"].cat.codes\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto_cat\"]\n",
    "obj_df[\"service\"] = obj_df[\"service_cat\"]\n",
    "obj_df[\"state\"] = obj_df[\"state_cat\"]\n",
    "\n",
    "obj_df.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_train_all_attacks = obj_df[\"attack_cat\"]\n",
    "obj_df=pd.get_dummies(obj_df, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_train = obj_df.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i,j] = round(X_train[i,j]/maximum,3)\n",
    "\n",
    "# Read in the testing CSV file \n",
    "print(\"Reading Testing csv file.\")\n",
    "df2 = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "df2.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df2=df2\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto\"].astype('category')\n",
    "obj_df2[\"service\"] = obj_df2[\"service\"].astype('category')\n",
    "obj_df2[\"state\"] = obj_df2[\"state\"].astype('category')\n",
    "obj_df2[\"proto_cat\"] = obj_df2[\"proto\"].cat.codes\n",
    "obj_df2[\"service_cat\"] = obj_df2[\"service\"].cat.codes\n",
    "obj_df2[\"state_cat\"] = obj_df2[\"state\"].cat.codes\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto_cat\"]\n",
    "obj_df2[\"service\"] = obj_df2[\"service_cat\"]\n",
    "obj_df2[\"state\"] = obj_df2[\"state_cat\"]\n",
    "\n",
    "obj_df2.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_test_all_attacks = obj_df2[\"attack_cat\"]\n",
    "obj_df2=pd.get_dummies(obj_df2, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_test = obj_df2.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i,j] = round(X_test[i,j]/maximum,3)\n",
    "\n",
    "\n",
    "estimators_number = list(range(10,30))\n",
    "\n",
    "dataspace = 0;\n",
    "overall_accuracy_matrix = [None]*len(X_train)\n",
    "iTERATION=0\n",
    "dataspace_number=1\n",
    "attack_type = 4\n",
    "Y_train = obj_df.values[:,-attack_type]\n",
    "Y_test = obj_df2.values[:,-attack_type]\n",
    "\n",
    "cleanup_nums = {\"Worms\":0, \"Shellcode\":1, \"Reconnaissance\":2, \"Normal\":3, \"Generic\":4, \"Fuzzers\":5, \"Exploits\":6, \"DoS\":7, \"Backdoor\":8, \"Analysis\":9}\n",
    "Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "Y_test_all_attacks.replace(cleanup_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['maximum', 'pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 43\n",
    "output_dim = 10\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 43\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[7,9],[3,8],[0,6],[4,2]]\n",
    "#task_labels = [[4,2], [0,6], [3,8], [9,7], [1,5],[8,9],[6,7],[5,5],[3,2],[0,1]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[0,9],[3,8],[0,6],[4,2],[3,5],[0,4],[9,6],[1,2]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 10\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_train[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_train[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_test[idx], np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_test[idx], np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    #print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    #print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "#model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "#model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax, input_shape=(input_dim,)))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "save_weights_epoch=[]\n",
    "save_loss_epoch=[]\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: save_weights_epoch.append(model.get_weights()))\n",
    "history = LossHistory()\n",
    "#history = History()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7f23308458c8>)], 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7f23308456a8>)], 'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7f232c1fc2f0>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7f232c1fc378>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7f232c1fc400>)], 'regularizer_fn': <function quadratic_regularizer at 0x7f2330845048>}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    imp_par = dict()  #Empty list to save importance parameter after learning each progressive task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=[print_weights])\n",
    "                save_loss_epoch.append(stuffs.history['loss'])\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save, imp_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "422/422 [==============================] - 0s - loss: 0.6847 - acc: 0.8957     \n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 0s - loss: 0.6640 - acc: 0.8957     \n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 0s - loss: 0.6360 - acc: 0.8957     \n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 0s - loss: 0.5994 - acc: 0.8957     \n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 0s - loss: 0.5533 - acc: 0.8957     \n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 0s - loss: 0.5030 - acc: 0.8957     \n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 0s - loss: 0.4526 - acc: 0.8957     \n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 0s - loss: 0.4125 - acc: 0.8957     \n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 0s - loss: 0.3796 - acc: 0.8957     \n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 0s - loss: 0.3604 - acc: 0.8957     \n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.1956 - acc: 0.9207     \n",
      "Epoch 2/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0955 - acc: 0.9623     \n",
      "Epoch 3/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0808 - acc: 0.9678     \n",
      "Epoch 4/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0764 - acc: 0.9690     \n",
      "Epoch 5/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0734 - acc: 0.9698     \n",
      "Epoch 6/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0724 - acc: 0.9704     \n",
      "Epoch 7/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0715 - acc: 0.9705     \n",
      "Epoch 8/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0699 - acc: 0.9713     \n",
      "Epoch 9/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0688 - acc: 0.9715     \n",
      "Epoch 10/10\n",
      "40496/40496 [==============================] - 0s - loss: 0.0677 - acc: 0.9723     \n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.2962 - acc: 0.8812     \n",
      "Epoch 2/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1862 - acc: 0.9168     \n",
      "Epoch 3/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1557 - acc: 0.9374     \n",
      "Epoch 4/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1411 - acc: 0.9522     \n",
      "Epoch 5/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1329 - acc: 0.9622     \n",
      "Epoch 6/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1260 - acc: 0.9682     \n",
      "Epoch 7/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1210 - acc: 0.9702     \n",
      "Epoch 8/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1115 - acc: 0.9699     \n",
      "Epoch 9/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0985 - acc: 0.9775     \n",
      "Epoch 10/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0898 - acc: 0.9795     \n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5087 - acc: 0.7298     \n",
      "Epoch 2/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4960 - acc: 0.7329     \n",
      "Epoch 3/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4943 - acc: 0.7350     \n",
      "Epoch 4/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4931 - acc: 0.7344     \n",
      "Epoch 5/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4920 - acc: 0.7350     \n",
      "Epoch 6/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4914 - acc: 0.7339     \n",
      "Epoch 7/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4910 - acc: 0.7353     \n",
      "Epoch 8/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4905 - acc: 0.7345     \n",
      "Epoch 9/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4902 - acc: 0.7361     \n",
      "Epoch 10/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.4902 - acc: 0.7382     \n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6934 - acc: 0.5286     \n",
      "Epoch 2/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6910 - acc: 0.5429     \n",
      "Epoch 3/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6954 - acc: 0.5294     \n",
      "Epoch 4/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6936 - acc: 0.5206     \n",
      "Epoch 5/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6915 - acc: 0.5373     \n",
      "Epoch 6/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6896 - acc: 0.5365     \n",
      "Epoch 7/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6897 - acc: 0.5365     \n",
      "Epoch 8/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6906 - acc: 0.5405     \n",
      "Epoch 9/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6900 - acc: 0.5294     \n",
      "Epoch 10/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6881 - acc: 0.5373     \n",
      "Age 5, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.2246 - acc: 0.9371     \n",
      "Epoch 2/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1973 - acc: 0.9401     \n",
      "Epoch 3/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1918 - acc: 0.9401     \n",
      "Epoch 4/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1883 - acc: 0.9401     \n",
      "Epoch 5/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1862 - acc: 0.9401     \n",
      "Epoch 6/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1847 - acc: 0.9401     \n",
      "Epoch 7/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1835 - acc: 0.9401     \n",
      "Epoch 8/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1822 - acc: 0.9401     \n",
      "Epoch 9/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1816 - acc: 0.9401     \n",
      "Epoch 10/10\n",
      "6440/6440 [==============================] - 0s - loss: 0.1806 - acc: 0.9401     \n",
      "Age 6, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.5460 - acc: 0.8242     \n",
      "Epoch 2/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.5058 - acc: 0.8580     \n",
      "Epoch 3/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4858 - acc: 0.8580     \n",
      "Epoch 4/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4765 - acc: 0.8580     \n",
      "Epoch 5/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4669 - acc: 0.8582     \n",
      "Epoch 6/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4614 - acc: 0.8580     \n",
      "Epoch 7/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4543 - acc: 0.8584     \n",
      "Epoch 8/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4504 - acc: 0.8584     \n",
      "Epoch 9/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4467 - acc: 0.8584     \n",
      "Epoch 10/10\n",
      "4766/4766 [==============================] - 0s - loss: 0.4425 - acc: 0.8586     \n",
      "Age 7, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0679 - acc: 0.9829     \n",
      "Epoch 2/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0649 - acc: 0.9831     \n",
      "Epoch 3/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0631 - acc: 0.9832     \n",
      "Epoch 4/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0621 - acc: 0.9832     \n",
      "Epoch 5/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0610 - acc: 0.9833     \n",
      "Epoch 6/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0602 - acc: 0.9834     \n",
      "Epoch 7/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0595 - acc: 0.9832     \n",
      "Epoch 8/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0589 - acc: 0.9831     \n",
      "Epoch 9/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0584 - acc: 0.9831     \n",
      "Epoch 10/10\n",
      "37583/37583 [==============================] - 0s - loss: 0.0579 - acc: 0.9832     \n",
      "Age 8, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0820 - acc: 0.9961     \n",
      "Epoch 2/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0586 - acc: 0.9961     \n",
      "Epoch 3/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0516 - acc: 0.9961     \n",
      "Epoch 4/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0473 - acc: 0.9961     \n",
      "Epoch 5/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0443 - acc: 0.9961     \n",
      "Epoch 6/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0419 - acc: 0.9961     \n",
      "Epoch 7/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0402 - acc: 0.9961     \n",
      "Epoch 8/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0386 - acc: 0.9961     \n",
      "Epoch 9/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0375 - acc: 0.9961     \n",
      "Epoch 10/10\n",
      "11176/11176 [==============================] - 0s - loss: 0.0365 - acc: 0.9961     \n",
      "Age 9, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0673 - acc: 0.9830     \n",
      "Epoch 2/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0635 - acc: 0.9836     \n",
      "Epoch 3/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0622 - acc: 0.9834     \n",
      "Epoch 4/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0613 - acc: 0.9837     \n",
      "Epoch 5/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0606 - acc: 0.9837     \n",
      "Epoch 6/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0602 - acc: 0.9834     \n",
      "Epoch 7/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0596 - acc: 0.9834     \n",
      "Epoch 8/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0591 - acc: 0.9837     \n",
      "Epoch 9/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0588 - acc: 0.9837     \n",
      "Epoch 10/10\n",
      "22367/22367 [==============================] - 0s - loss: 0.0584 - acc: 0.9836     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:22<00:00, 82.13s/it]\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save,imp_par = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 43)                1892      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                440       \n",
      "=================================================================\n",
      "Total params: 2,332\n",
      "Trainable params: 2,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(43, 43)\n",
      "(43,)\n",
      "(43, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2Attack_Accuracy_10task.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89707047 0.89707047 0.89707047 0.89707047 0.89707047 0.10292953\n",
      " 0.10292953 0.10292953 0.89707047 0.89707047] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.21184822 0.84221925 0.84221925 0.84221925 0.84221925 0.84221925\n",
      " 0.84221925 0.84221925 0.84221925 0.86849348] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.68754297 0.10867249 0.30274646 0.30272927 0.30272927 0.30293551\n",
      " 0.30293551 0.30293551 0.30293551 0.30302145] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.73149791 0.7313884  0.7313884  0.66990823 0.66990823 0.66990823\n",
      " 0.656263   0.6553212  0.66114725 0.66178242] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.53470368 0.56326749 0.56567005 0.56326749 0.56940737 0.56940737\n",
      " 0.46609717 0.48478377 0.48478377 0.48478377] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.058653   0.058653   0.90826733 0.90821556 0.90821556 0.941347\n",
      " 0.941347   0.941347   0.941347   0.941347  ] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.14329781 0.21662928 0.21655917 0.66727426 0.66832586 0.66825575\n",
      " 0.73058048 0.73114133 0.73121144 0.73142176] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.93121601 0.96976414 0.96976414 0.96976414 0.96976414 0.96976414\n",
      " 0.96976414 0.96976414 0.96976414 0.96976414] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.99612207 0.99612207 0.99612207 0.99397429 0.99397429 0.99397429\n",
      " 0.99391463 0.99391463 0.99612207 0.99612207] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.7922204  0.7922204  0.13647977 0.12160583 0.12338833 0.11550573\n",
      " 0.11304985 0.11217841 0.11217841 0.19058842] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(1,n_tasks+1), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0.5, 8.5)\n",
    "ylim(0.5, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('2attack_fractional_correct_UNSW.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Autocorrelation Matrix for task= 0 is : 24\n",
      "Rank of the Autocorrelation Matrix for task= 1 is : 36\n",
      "Rank of the Autocorrelation Matrix for task= 2 is : 36\n",
      "Rank of the Autocorrelation Matrix for task= 3 is : 38\n",
      "Rank of the Autocorrelation Matrix for task= 4 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 5 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 6 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 7 is : 40\n",
      "Rank of the Autocorrelation Matrix for task= 8 is : 41\n",
      "Rank of the Autocorrelation Matrix for task= 9 is : 41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import matrix_rank\n",
    "import math\n",
    "corr_matrix = []\n",
    "corr_row = []\n",
    "Rank_corr_matrix=[]\n",
    "for j in range(n_tasks):\n",
    "    df = pd.DataFrame(training_datasets[j][0])\n",
    "    correlation_matrix = df.corr().values\n",
    "    correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "    for k in range(len(correlation_matrix)):\n",
    "        for i in range(len(correlation_matrix)):\n",
    "            corr_elem = (math.ceil(correlation_matrix[k][i]*1e10)/1e10)\n",
    "            corr_row.append(np.around(corr_elem))\n",
    "        corr_matrix.append(corr_row)\n",
    "        corr_row = []\n",
    "    rank_corr_matrix=np.linalg.matrix_rank(np.asarray(corr_matrix))\n",
    "    Rank_corr_matrix.append(rank_corr_matrix)\n",
    "    print('Rank of the Autocorrelation Matrix for task=',j,'is :',rank_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+50 \n",
    "for i in range(n_tasks):   \n",
    "    Extract_model_params.append(Flatten_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(save_weights_epoch),len(model_weights_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 854\n",
      "Rank of the Hessian Matrix after task= 1 is : 1661\n",
      "Rank of the Hessian Matrix after task= 2 is : 1774\n",
      "Rank of the Hessian Matrix after task= 3 is : 1948\n",
      "Rank of the Hessian Matrix after task= 4 is : 1993\n",
      "Rank of the Hessian Matrix after task= 5 is : 2034\n",
      "Rank of the Hessian Matrix after task= 6 is : 2065\n",
      "Rank of the Hessian Matrix after task= 7 is : 2085\n",
      "Rank of the Hessian Matrix after task= 8 is : 2099\n",
      "Rank of the Hessian Matrix after task= 9 is : 2104\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    if i == 0:\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-2])))\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-1])))\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(len(Flatten_weights)):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    if i == 2:\n",
    "        pass\n",
    "    else :\n",
    "        temp=list(np.asarray(Extract_model_params[i])-np.asarray(Extract_model_params[i-1]))\n",
    "        gradient = [j/0.001 for j in temp]\n",
    "        gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 932\n",
      "Rank of the Hessian Matrix after task= 1 is : 1737\n",
      "Rank of the Hessian Matrix after task= 2 is : 1800\n",
      "Rank of the Hessian Matrix after task= 3 is : 1870\n",
      "Rank of the Hessian Matrix after task= 4 is : 1902\n",
      "Rank of the Hessian Matrix after task= 5 is : 1967\n",
      "Rank of the Hessian Matrix after task= 6 is : 2071\n",
      "Rank of the Hessian Matrix after task= 7 is : 2117\n",
      "Rank of the Hessian Matrix after task= 8 is : 2130\n",
      "Rank of the Hessian Matrix after task= 9 is : 2134\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "                \n",
    "for i in range(n_tasks):\n",
    "    Flatten_weights.append(list(flatten(save_weights_epoch[(i+1)*epochs_per_task-2])))\n",
    "    Flatten_weights.append(list(flatten(save_weights_epoch[(i+1)*epochs_per_task-1])))\n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(len(Flatten_weights)):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params),2):\n",
    "    temp=list(np.asarray(Extract_model_params[i])-np.asarray(Extract_model_params[i-1]))\n",
    "    \n",
    "    gradient = [j/0.001 for j in temp]\n",
    "    gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucledian Parameter shift after task 1 : 18.42116476268859\n",
      "Eucledian Parameter shift after task 2 : 9.208601450530098\n",
      "Eucledian Parameter shift after task 3 : 3.934590313084037\n",
      "Eucledian Parameter shift after task 4 : 0.7763082720953064\n",
      "Eucledian Parameter shift after task 5 : 2.4158320680373264\n",
      "Eucledian Parameter shift after task 6 : 2.6746329869635184\n",
      "Eucledian Parameter shift after task 7 : 5.5886347410127915\n",
      "Eucledian Parameter shift after task 8 : 3.289132188129787\n",
      "Eucledian Parameter shift after task 9 : 3.2878901208808284\n",
      "Cosine Parameter shift after task 1 : 0.132\n",
      "Cosine Parameter shift after task 2 : 0.891\n",
      "Cosine Parameter shift after task 3 : 0.981\n",
      "Cosine Parameter shift after task 4 : 0.999\n",
      "Cosine Parameter shift after task 5 : 0.993\n",
      "Cosine Parameter shift after task 6 : 0.992\n",
      "Cosine Parameter shift after task 7 : 0.966\n",
      "Cosine Parameter shift after task 8 : 0.989\n",
      "Cosine Parameter shift after task 9 : 0.989\n",
      "Jaccard Parameter shift after task 1 : 0.16968781470292044\n",
      "Jaccard Parameter shift after task 2 : 0.21566579634464753\n",
      "Jaccard Parameter shift after task 3 : 0.16733466933867736\n",
      "Jaccard Parameter shift after task 4 : 0.2149557060969255\n",
      "Jaccard Parameter shift after task 5 : 0.1787158746208291\n",
      "Jaccard Parameter shift after task 6 : 0.16837885241794037\n",
      "Jaccard Parameter shift after task 7 : 0.16396306463688545\n",
      "Jaccard Parameter shift after task 8 : 0.16862941618641944\n",
      "Jaccard Parameter shift after task 9 : 0.19835560123329907\n",
      "Heuristic Parameter shift after task 1 : 0.2911663807890223\n",
      "Heuristic Parameter shift after task 2 : 0.35548885077186965\n",
      "Heuristic Parameter shift after task 3 : 0.2868782161234991\n",
      "Heuristic Parameter shift after task 4 : 0.35377358490566035\n",
      "Heuristic Parameter shift after task 5 : 0.3031732418524871\n",
      "Heuristic Parameter shift after task 6 : 0.2881646655231561\n",
      "Heuristic Parameter shift after task 7 : 0.28173241852487135\n",
      "Heuristic Parameter shift after task 8 : 0.2885934819897084\n",
      "Heuristic Parameter shift after task 9 : 0.33104631217838765\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "from math import*\n",
    "#1. Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "#2. Manhattan Distance\n",
    "def manhattan_distance(x,y):\n",
    "    return sum(abs(a-b) for a,b in zip(x,y))\n",
    "#3.  Minkowski distance \n",
    "from decimal import Decimal\n",
    "def nth_root(value, n_root):\n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def minkowski_distance(x,y,p_value):\n",
    "    return nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),p_value)\n",
    "#4. Cosine Similarity\n",
    "def square_rooted(x):\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "#5. Jaccard similarity\n",
    "def jaccard_similarity(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "#6. Using Heuristic    \n",
    "import difflib \n",
    "\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Eucledian Parameter shift after task {0} :\".format(i+1),euclidean_distance(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Cosine Parameter shift after task {0} :\".format(i+1),cosine_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Jaccard Parameter shift after task {0} :\".format(i+1),jaccard_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Heuristic Parameter shift after task {0} :\".format(i+1),difflib.SequenceMatcher(None,Extract_model_params[i],Extract_model_params[i+1]).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of changed parameters\n",
    "changed_model_parameters=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    temp=[]\n",
    "    for j,k in zip(Extract_model_params[i],Extract_model_params[i-1]):\n",
    "        temp.append(abs(i-j))\n",
    "    changed_model_parameters.append(temp)\n",
    "print(len(changed_model_parameters))\n",
    "\n",
    "import csv\n",
    "#Save the model parameters in text file\n",
    "with open('temp', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(Extract_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----After learning 2 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 1\n",
      "0.1 ----> 14\n",
      "-----After learning 3 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 4 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n",
      "-----After learning 5 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n"
     ]
    }
   ],
   "source": [
    "#Number of parameters unchanged within the thresold. Checked for five threshold values as [1e-5, 1e-4, 1e-3, 1e-2, 1e-1].\n",
    "for i in range(len(changed_model_parameters)):\n",
    "    print('-----After learning',i+2,'task-----')\n",
    "    for j in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "        print(j,'---->',sum(k < j for k in changed_model_parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
