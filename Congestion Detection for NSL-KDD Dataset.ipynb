{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n",
      "(148515, 41) (148515,)\n",
      "(99505, 41) (49010, 41)\n"
     ]
    }
   ],
   "source": [
    "#Type-1\n",
    "print(\"Reading Training csv file.\")\n",
    "df1 = pd.read_csv(\"KDDTrain+.txt\")\n",
    "print(\"Reading Testing csv file.\")\n",
    "df2 = pd.read_csv(\"KDDTest+.txt\")\n",
    "df1.drop(df1.columns[-1], axis=1, inplace=True)  \n",
    "df2.drop(df2.columns[-1], axis=1, inplace=True)  \n",
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"])\n",
    "\n",
    "df1.columns = col_names\n",
    "df2.columns = col_names\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['labels'])\n",
    "df['labels'] = le.transform(df['labels'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['protocol_type'])\n",
    "df['protocol_type'] = le.transform(df['protocol_type'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['service'])\n",
    "df['service'] = le.transform(df['service'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['flag'])\n",
    "df['flag'] = le.transform(df['flag'])\n",
    "\n",
    "X= df.values[:,:-1]\n",
    "Y = df.values[:,-1]\n",
    "Y = Y.astype(int)\n",
    "print (X.shape,Y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train_all_attacks, Y_test_all_attacks = train_test_split(X, Y, test_size=0.33)\n",
    "print (X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n",
      "(125972, 41) (22543, 41) (125972,) (22543,)\n"
     ]
    }
   ],
   "source": [
    "#Type-2\n",
    "print(\"Reading Training csv file.\")\n",
    "df1 = pd.read_csv(\"KDDTrain+.txt\")\n",
    "print(\"Reading Testing csv file.\")\n",
    "df2 = pd.read_csv(\"KDDTest+.txt\")\n",
    "df1.drop(df1.columns[-2], axis=1, inplace=True)  \n",
    "df2.drop(df2.columns[-2], axis=1, inplace=True)  \n",
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"])\n",
    "\n",
    "df1.columns = col_names\n",
    "df2.columns = col_names\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df1['protocol_type'])\n",
    "df1['protocol_type'] = le.transform(df1['protocol_type'])\n",
    "df2['protocol_type'] = le.transform(df2['protocol_type'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df1['service'])\n",
    "df1['service'] = le.transform(df1['service'])\n",
    "df2['service'] = le.transform(df2['service'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df1['flag'])\n",
    "df1['flag'] = le.transform(df1['flag'])\n",
    "df2['flag'] = le.transform(df2['flag'])\n",
    "\n",
    "     \n",
    "\n",
    "X_train= df1.values[:,:-1]\n",
    "X_test= df2.values[:,:-1]\n",
    "Y_train_all_attacks = df1.values[:,-1]\n",
    "Y_test_all_attacks = df2.values[:,-1]\n",
    "Y_train_all_attacks = Y_train_all_attacks.astype(int)\n",
    "Y_test_all_attacks = Y_test_all_attacks.astype(int)\n",
    "print (X_train.shape,X_test.shape,Y_train_all_attacks.shape,Y_test_all_attacks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Type-1 is used here\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 41\n",
    "output_dim = 22\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 41\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "#task_labels = [[0,1],[2,3],[4,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,17],[18,19],[20,21],[22,23],[24,25],[26,27],[28,29],[30,31],[32,33],[34,35],[36,37],[38,39]]\n",
    "#nb_classes  = 40\n",
    "#task_labels = [[0,5],[2,3],[1,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,17],[18,19],[20,21]]\n",
    "nb_classes  = 22\n",
    "task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1],[10,11],[12,13],[14,15],[16,17]]\n",
    "#task_labels = [[2,3], [4,5], [6,7], [8,9],[10,11]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[0,9],[3,8],[0,6],[4,2],[3,5],[0,4],[9,6],[1,2]]\n",
    "n_tasks = len(task_labels)\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_train[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_train[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_test[idx], np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_test[idx], np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 0 (22, 41) (22, 22) (14, 41) (14, 22)\n",
      "Task: 1 (2561, 41) (2561, 22) (1191, 41) (1191, 22)\n",
      "Task: 2 (957, 41) (957, 22) (460, 41) (460, 22)\n",
      "Task: 3 (44, 41) (44, 22) (17, 41) (17, 22)\n",
      "Task: 4 (1359, 41) (1359, 22) (693, 41) (693, 22)\n",
      "Task: 5 (888, 41) (888, 22) (401, 41) (401, 22)\n",
      "Task: 6 (31, 41) (31, 22) (11, 41) (11, 22)\n",
      "Task: 7 (31720, 41) (31720, 22) (15716, 41) (15716, 22)\n",
      "Task: 8 (51700, 41) (51700, 22) (25358, 41) (25358, 22)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_tasks):\n",
    "    print('Task:',i,training_datasets[i][0].shape,training_datasets[i][1].shape,validation_datasets[i][0].shape,validation_datasets[i][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    #print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    #print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "#model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "model.add(Dense(30, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='zero', activation=masked_softmax))\n",
    "#model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax, input_shape=(input_dim,)))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "save_weights_epoch=[]\n",
    "save_loss_epoch=[]\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: save_weights_epoch.append(model.get_weights()))\n",
    "history = LossHistory()\n",
    "#history = History()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularizer_fn': <function quadratic_regularizer at 0x7f3673fc5e18>, 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7f3648686ae8>)], 'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7f364868b6a8>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7f364879b6a8>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7f364879b488>)], 'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7f364868bb70>)]}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    imp_par = dict()  #Empty list to save importance parameter after learning each progressive task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=[print_weights])\n",
    "                save_loss_epoch.append(stuffs.history['loss'])\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save, imp_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 0s - loss: 0.6931 - acc: 0.6364\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 0s - loss: 0.5398 - acc: 0.4545\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 0s - loss: 0.4975 - acc: 0.5455\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 0s - loss: 0.4741 - acc: 0.9091\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 0s - loss: 0.4592 - acc: 0.9545\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 0s - loss: 0.4484 - acc: 0.9545\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 0s - loss: 0.4396 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 0s - loss: 0.4314 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 0s - loss: 0.4230 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 0s - loss: 0.4141 - acc: 1.0000\n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.2256 - acc: 0.9727        \n",
      "Epoch 2/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0325 - acc: 0.9977     \n",
      "Epoch 3/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0253 - acc: 0.9977     \n",
      "Epoch 4/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0201 - acc: 0.9977        \n",
      "Epoch 5/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0164 - acc: 0.9977        \n",
      "Epoch 6/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0152 - acc: 0.9977        \n",
      "Epoch 7/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0147 - acc: 0.9977        \n",
      "Epoch 8/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0143 - acc: 0.9977        \n",
      "Epoch 9/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0140 - acc: 0.9977        \n",
      "Epoch 10/10\n",
      "2561/2561 [==============================] - 0s - loss: 0.0137 - acc: 0.9992        \n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "957/957 [==============================] - 0s - loss: 0.3598 - acc: 0.9352     \n",
      "Epoch 2/10\n",
      "957/957 [==============================] - 0s - loss: 0.1746 - acc: 0.9875     \n",
      "Epoch 3/10\n",
      "957/957 [==============================] - 0s - loss: 0.1700 - acc: 0.9896         \n",
      "Epoch 4/10\n",
      "957/957 [==============================] - 0s - loss: 0.1700 - acc: 0.9896     \n",
      "Epoch 5/10\n",
      "957/957 [==============================] - 0s - loss: 0.1700 - acc: 0.9896     \n",
      "Epoch 6/10\n",
      "957/957 [==============================] - 0s - loss: 0.1697 - acc: 0.9896     \n",
      "Epoch 7/10\n",
      "957/957 [==============================] - 0s - loss: 0.1696 - acc: 0.9896     \n",
      "Epoch 8/10\n",
      "957/957 [==============================] - 0s - loss: 0.1695 - acc: 0.9896         \n",
      "Epoch 9/10\n",
      "957/957 [==============================] - 0s - loss: 0.1693 - acc: 0.9896     \n",
      "Epoch 10/10\n",
      "957/957 [==============================] - 0s - loss: 0.1692 - acc: 0.9896         \n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 0s - loss: 0.6931 - acc: 0.8182\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s - loss: 1.3979 - acc: 0.8182\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s - loss: 1.5703 - acc: 0.8182\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s - loss: 1.6409 - acc: 0.8409\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s - loss: 1.6168 - acc: 0.8409\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s - loss: 1.5229 - acc: 0.8409\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s - loss: 1.3899 - acc: 0.8409\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s - loss: 1.2487 - acc: 0.8864\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s - loss: 1.0093 - acc: 0.8864\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s - loss: 0.9468 - acc: 0.7955\n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "1359/1359 [==============================] - 0s - loss: 3.6939 - acc: 0.7380     \n",
      "Epoch 2/10\n",
      "1359/1359 [==============================] - 0s - loss: 3.7617 - acc: 0.7660     \n",
      "Epoch 3/10\n",
      "1359/1359 [==============================] - 0s - loss: 3.7607 - acc: 0.7660     \n",
      "Epoch 4/10\n",
      "1359/1359 [==============================] - 0s - loss: 3.7598 - acc: 0.7667     \n",
      "Epoch 5/10\n",
      "1359/1359 [==============================] - 0s - loss: 3.7601 - acc: 0.7667     \n",
      "Epoch 6/10\n",
      "1359/1359 [==============================] - 0s - loss: 4.4836 - acc: 0.7182     \n",
      "Epoch 7/10\n",
      "1359/1359 [==============================] - 0s - loss: 10.2591 - acc: 0.3635     \n",
      "Epoch 8/10\n",
      "1359/1359 [==============================] - 0s - loss: 10.2591 - acc: 0.3635     \n",
      "Epoch 9/10\n",
      "1359/1359 [==============================] - 0s - loss: 10.2591 - acc: 0.3635    \n",
      "Epoch 10/10\n",
      "1359/1359 [==============================] - 0s - loss: 10.2591 - acc: 0.3635     \n",
      "Age 5, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "888/888 [==============================] - 0s - loss: 0.2206 - acc: 0.8277     \n",
      "Epoch 2/10\n",
      "888/888 [==============================] - 0s - loss: 0.0136 - acc: 1.0000     \n",
      "Epoch 3/10\n",
      "888/888 [==============================] - 0s - loss: 0.0076 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "888/888 [==============================] - 0s - loss: 0.0078 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "888/888 [==============================] - 0s - loss: 0.0068 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "888/888 [==============================] - 0s - loss: 0.0061 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "888/888 [==============================] - 0s - loss: 0.0056 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "888/888 [==============================] - 0s - loss: 0.0057 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "888/888 [==============================] - 0s - loss: 0.0049 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "888/888 [==============================] - 0s - loss: 0.0051 - acc: 1.0000     \n",
      "Age 6, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s - loss: 0.6931 - acc: 0.6129\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s - loss: 1.0157 - acc: 0.6774\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s - loss: 1.0323 - acc: 0.7097\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s - loss: 1.1210 - acc: 0.7097\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s - loss: 1.1669 - acc: 0.7419\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s - loss: 1.0770 - acc: 0.7419\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s - loss: 0.9423 - acc: 0.7742\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s - loss: 1.8795 - acc: 0.7097\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s - loss: 1.8150 - acc: 0.7097\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s - loss: 1.7371 - acc: 0.7742\n",
      "Age 7, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0230 - acc: 0.9930     \n",
      "Epoch 2/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0063 - acc: 0.9986     \n",
      "Epoch 3/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0041 - acc: 0.9993     \n",
      "Epoch 4/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0027 - acc: 0.9998     \n",
      "Epoch 5/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0023 - acc: 0.9998     \n",
      "Epoch 6/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0024 - acc: 0.9996     \n",
      "Epoch 7/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0023 - acc: 0.9997     \n",
      "Epoch 8/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0016 - acc: 0.9999     \n",
      "Epoch 9/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0021 - acc: 0.9997     \n",
      "Epoch 10/10\n",
      "31720/31720 [==============================] - 0s - loss: 0.0014 - acc: 0.9999     \n",
      "Age 8, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0026 - acc: 0.9999     \n",
      "Epoch 2/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0014 - acc: 0.9999     \n",
      "Epoch 3/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0013 - acc: 0.9999      \n",
      "Epoch 4/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0012 - acc: 0.9999     \n",
      "Epoch 5/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0011 - acc: 0.9999      \n",
      "Epoch 6/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0011 - acc: 0.9999       \n",
      "Epoch 7/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0010 - acc: 0.9999      \n",
      "Epoch 8/10\n",
      "51700/51700 [==============================] - 1s - loss: 0.0010 - acc: 0.9999     \n",
      "Epoch 9/10\n",
      "51700/51700 [==============================] - 1s - loss: 9.9072e-04 - acc: 0.9999 \n",
      "Epoch 10/10\n",
      "51700/51700 [==============================] - 1s - loss: 9.7535e-04 - acc: 0.9999     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.83s/it]\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save,imp_par = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 41)                1722      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                1260      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 22)                682       \n",
      "=================================================================\n",
      "Total params: 3,664\n",
      "Trainable params: 3,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(41, 41)\n",
      "(41,)\n",
      "(41, 30)\n",
      "(30,)\n",
      "(30, 22)\n",
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "        axs[j].set_xticks(range(0,n_tasks))\n",
    "        axs[j].set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        if j == 0:\n",
    "            axs[j].set_xlabel('Trained Tasks') \n",
    "            axs[j].set_ylabel('Accuracy(*100%)') \n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "    \n",
    "ylim(0,1)\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2taskprogressive-NSL-KDD.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.78571429 0.78571429 0.78571429\n",
      " 0.78571429 0.78571429 0.78571429] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.00503778 0.99832074 0.99832074 0.99832074 0.99832074 0.99832074\n",
      " 0.99076406 0.98656591 0.98656591] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.91086957 0.91086957 0.76086957 0.08913043 0.08913043 0.08913043\n",
      " 0.08913043 0.08913043 0.08913043] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.82352941 0.82352941 0.82352941 0.23529412 0.23529412 0.23529412\n",
      " 0.23529412 0.23529412 0.23529412] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.35064935 0.35064935 0.35064935 0.35064935 0.35064935 0.35064935\n",
      " 0.35064935 0.35064935 0.35064935] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.21446384 0.21446384 0.21446384 0.21446384 0.21446384 1.\n",
      " 1.         1.         1.        ] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.54545455 0.54545455 0.54545455 0.54545455 0.54545455 0.54545455\n",
      " 0.54545455 0.54545455 0.54545455] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.96812166 0.96812166 0.96812166 0.96812166 0.96812166 0.96812166\n",
      " 0.96812166 0.99980911 0.99980911] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.99992113 0.99992113 0.99992113 0.99992113 0.99992113 0.99992113\n",
      " 0.99992113 0.99992113 0.99992113] [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9991603694374476, 0.9197301013640956, 0.527114894254712, 0.49182178553363975, 0.5765181546113665, 0.571000971151396, 0.6240772196225344, 0.6658376540452096]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOYAAACsCAYAAABvqdCxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAHdlJREFUeJzt3XtclHX6//HXcBhBUU6KHEQ0DygqX1R01XLTKE+ose2aoYtapptFapKliYf96ZoutmnudtBcD6RmZFoeylbNTROlUARUPCeCoImOggzn+f1BzDoNMIADcwPX8/Ho0TA3c8+F8vb+zOf+3Pel0ul0OoQQimJl6QKEEMYkmEIokARTCAWSYAqhQBJMIRRIgimEAkkwhVAgCaYQCiTBFEKBJJhCKFC9CGZRURFpaWkUFRVZuhQh6kS9CGZmZiZBQUE8tnAHO0+mP9S+dp5M59FlB2k/Zw+PLjv40PsTojbUSjBv3LjBH/7wB3r06GF0lDt//jyhoaE899xzpKSkVGu/mffymPtFUo3DtPNkOnO/SCJdo0UHpGu0D7U/IWqLqjauLsnPzycvL4/w8HDWr1+PjY2Nftsrr7xCZGQkVlZWLFq0iA8++MDk/tLS0ggKCiJ/SCQ0c8GqUItz6iF+16cPQUFBFBYWsCIqCtChQge//kiDBw8i6IknyM6+x9+XLedWh6GU2DYz2n9rB1vs9y81ej4iIoJRo0Zx7tw5/vKXvxhtj4yM5MknnyQhIYGZM2cabV+6dCkDBgzg6NGjvPXWW0bbV65cSUBAAPv372fJkiVG2z/66CN8fX3ZtWsX77zzjtH26OhovL292bZtW7l/jp9//jktW7Zkw4YNbNiwwWj73r17adq0Ke+//z6fffaZ0fZDhw4BsGLFCnbv3m2wzd7enq+//hqAxYsXc+DAAYPtrq6ubN++HYC5c+cSGxtrsL1NmzZ88sknAMycOZOEhASD7Z07d2bNmjUATJ06lfPnzxtsDwgIYOXKlQD8+c9/Ji0tzWB7//79efvttwH44x//SFZWlsH2oKAg5s+fD8Dw4cPRarUG20eOHMnrr78OwKBBg/itZ599lpdffpnc3FxGjBhhtH3SpElMmjSJW7du0bJlS6PtptiY/pbqa9KkCU2aNCl327179/Dw8AAgOzvbaPu2bdvYtm2bwXMFBQUGX5fY2pPVYTh7b8PemFOlT3YaabSvz9Lhs+j40i+6PFNhvTdzCvGpcKsQda9WjphlwsLCjI6Y48ePZ/PmzUaPK/PbI2brFk34/KUBAJTodJToQPfA/3Vlz5eADh06XenXkzf8xC85+Ub7d2vehLh5T5rnhxbCDGrliFkZlUqlf2xlVf2PuPa21swd3hVvl6bVfu284K7M/SIJbWGxwfO/ZOezdO9Zpgd1wqFJnf+RCGGkzn8LHR0dyczMRKVS0ayZ8ee9yri3sGPOMz0I6elVo/cue13UvnNc12jxdLJn2qAOJKXdZc33l/kyIZ3IYD9G+nsY/AMiRF2rlaFsYWEhU6ZM4fTp0/j5+fHKK68QHx/PtGnTSElJYdGiRQAsXLiQrl27mtxf2VD2wIEDtGnTxtzlAnAi9Q7zdyZz+vo9Hu3oyl9Hd6ejm0OtvJcQptTqZ0xzqYtgAhSX6Nhy/CpR+86hLSxm8mOPMD2oI03VMrwVdateLDCoK9ZWKsL6t+Pg64N4OsCLD/97iSff+S9fJ2VQD/79arDGfhTL2I9iTX9jAyLBLEdLhyasGPN/fP5Sfxybqpm2+QQT/h3H5V9yLF2asJDJkycTGBhY7vns2iDBrERgOxd2hT/KolF+JKRqGLbyMCv2nUNbUGz6xcIsdp5M52SqhuNXblt0CeWLL77I3//+9zp7P/nwZIKNtRWTHm3PCH8Plu1N4Z/fXWTHyXQWjPIjN7+IFd+e18/wzh7qW+MZY2GsbAllQXEJ8L8llMBD/Tnv3LmTdevWoVKp8PX1JSoqyuRr+vfvz/Hjx2v8ntUlwawit+Z2/GNsAGP7eLPgy9P8JToeKxWU/PrR01y/NI3J9vg0PvvpWoXbT6Zq9KEsoy0s5o3PE9kal1rua54N9OaPvSueILxw4QIffPABW7duxcXFBY1Gw1dffcW6deuMvtfHx4f33nuvij+NeUkwq+l3j7iye/pjBC75D3e1hgv0tYXFRO07J8E0k9+G0tTzVXHs2DGGDRuGi4sLAE5OTowePZrRo0fXeJ+1QYJZA7bWVtzTln9t6HWNttznhbE/9m5T6dHt0WUHSS/nz9PLyZ5tf+lvtjrkiNmAeDrZl/tL4+lkb4FqGqbZQ32NllDa21oze6hvjffZr18/wsPDmTRpEs7Ozmg0GkUeMWVWtoZmD/XF3tba4LmH/aURhkJ6evH2Mz1QW5f+mno52fP2QyzJBOjUqRMvvfQSYWFhjB49mmXLllXpdePGjWPGjBnExsby+9//nsOHD9e4hqqQlT8PYefJdKL2ndMfOf862o+JA9pbuKqGp2xxgTmHr0onQ9mHENLTi5CeXly4kc1T736P8v+Jq58aUyDLyFDWDDq1bo5v6+bsScqwdCmigZBgmkmwvwc//nyHzLt5li5FNAASTDMZ0aP0dil75agpzECCaSYd3Rzo4i7DWWEeEkwzGunvQfzVO7LIQDw0CaYZlQ1nv07OtHAlor6TYJrRI60c8PNowZ7E65YuRdRzEkwzC/b34ESqptzlekJUlQTTzILLhrMyCSQeggTTzNq1bEZ3rxbsTpRgipqrtWAuXbqUcePGGfXk+Prrr/nTn/7EmDFj2L9/f229vUUF9/Ak4ZqGa7dzLV2KqKdMBvP55583+HrWrFkmd3r69Glyc3PZsmULhYWFJCYm6rdt3LiR6OhooqOjy2100xDoh7PJctQUNVPhIvZjx45x7Ngxrl69yqpVqwAoLi7m5s2bJneakJDAgAGlvUUGDBhAQkIC/v7+AHh7e+s7Kzk4NMwbKrd1bYp/G0f2JGYw9fcdLF2OqIcqDKa3tzdWVlZcu3aN/v1LV/fb2NgwdepUkzvNzs7G29sbgObNm3PhwgX9tqeeeoqQkBB0Op2+TdqDqtLtqz4I7uHB21+ncO12bo36rIjGrcJgenl54eXlRVZWFn379gVKO2l98803DB8+vNKdNm/enJyc0nuw5uTk0KJFC/22f/3rX+zduxeAKVOm8Nhjjxm8duzYsYwdO9bgubLrMeuTEb8Gc09SBi89LkdNUT0mP2Nu3bpV/1ilUvHpp5+a3GlAQADHjh0D4OjRowQEBOi3qdVq7OzssLe3p7CwsCY11wveLk35v1+Hs0JUl8lgFhYWcvfuXQA0Gg35+cb9JX+rW7duqNVqxo0bh7W1NR4eHvqOx6GhofpW7789MjY0wf4eJKXf5WrWfUuXIuoZk7cWiY+P591330Wn02FlZcVrr71Gr1696qo+QLm3FjEl7U4ujy3/jjeG+fLyoI6WLkfUIyZvLdK7d2/Wr1/P7du3ad26dV3U1GC0cW5KgLcTe5MyJJiiWkwOZXfs2MHUqVOZMmUKxcXFTJ8+vS7qajBG+nuQnH6Pn2/JcFZUnclgxsTEsH79ehwdHbG2tkaj0dRFXQ3G8F8XG8gF1KI6TAbT2tqa+/fvo1KpyMvLkxbo1eTlZE+vtk4yOyuqxWQwZ8+ezfTp07l8+TLTp08nIiKiLupqUIL9PTmTcU/6a4oqq3TyR6fTcfHixXL7OoiqG9HDncW7z7A3KYPwJzpZuhxRD1R6xFSpVPz3v/+tq1oaLA9HewJ9nOVSMFFlJk+X3Llzh1GjRuHr64tKpUKlUtVpZ92GItjfg7/uOsPFmzl0dGuYi/eF+ZgM5uzZs/W9BEXNDe/uwf/7dTg7PUiGs6JyJid/Vq5cqV/QXvafqD53Rzv6+LjI7KyoEpPBdHNzY82aNRw9epTY2FhiY2Proq4GKdjfg3M3srlwI9vSpQiFMxlMLy8vCgoKOHHiBPHx8cTHx9dFXQ3S8O7uqFSy2ECYZvIzZnh4OL/88gtpaWl4eXnh5uZWF3U1SG4t7OjTrnQ4O/PJzpYuR5SjrOfpdY0WTyd7Zg/1fahGuTVlMpgff/wxx48fp0uXLpw5c4Z+/foxZcqUuqitQRrp78GCL09z/kY2nVs3t3Q54gE7T6YbtJZP12iZ+0USQJ2H0+RQ9uDBg6xdu5aIiAjWrVvHwYMH66KuBmtY2XBWJoEU5WrWfRZ8mawPZRltYTFR+87VeT0mj5i2tracOHECPz8/kpOTsbGRJtQPw625Hb9r78KepAxmPtlJ1h5biE6n40zGPfadvsG3pzNJyax4Qs4STaJMpmzZsmWsXbuW999/Hx8fH5YvX14XdTVowf6ezN+ZzPkbOfi6y3C2rhSX6Ii/eod9pzPZdzqTtDtaVCro4+PC/JF+rPn+EjfuGd+hw9PJvs5rNRnM/Px85s+fj0qlQqfTcfXq1bqoq0Eb1s2dhV8msyfxOr7uvpYup0HLLyrm6KUs9iVnsv/sDW7lFKC2tuLRjq6ED+7Ik36taenQBADXZmqDz5gA9rbWzB5a939HJoO5cOFCNm7cCJSunX3wa1EzrZo3od8jruxOyuC1pzrLcPYhlDeL+qRfaw6du8m+0zf4LuUmOflFNFNbM7iLG0O7uTPItxXN7WyN9lU2wVMvZmXz8vL0j3U6ncHXouaC/T2YtyOZlMxsunq0MP0CYaS8WdRZnyWgAop1pUfA4B4eDOvuzoCOrjSxsTa5z5CeXhYJ4m+ZDGZISAiTJk3Cz8+Ps2fPEhISUhd1NXjDurkzf2cyexIzJJg19Pd9KUazqCU6aNbEmn9P7ENgOxesrernaMRkMENDQxk6dChpaWm8+OKLsqDdTFwdmjCgQ0v2JGUQMUSGs9WReTePbT9e47qm/NFbbn4xv3vEtY6rMq8qnftwcXGpdiCXLl1KcnIyfn5+REZG6p/XaDQsXLiQO3fu0L9/f6ZNm1a9ihuQYH8P5n6RxJmMe3TzdLR0OYpWXKLj+wu/sOV4KgdTblJcoqOJjRX5RSVG32uJWVRzq5WTkg92+1q4cCGJiYn6pkL//Oc/mT59Oh06SNuAod3cifx1OCvBLN/Ne3l89tM1tsZdI12jxbWZmikDHyG0rzcnUzWKmUU1tyoFMycnh+zsbMruDe3p6Vnp91fW7evChQt89NFHZGRkMGvWLHr27Gnw2obSVKgqXJqpGdDBlT1JGcwe6ivD2V+VlOj44dItNh9LZf/ZGxSV6BjQwZW5I7owxM8dtU3pgjUf12aAMmZRzc1kMOfPn8/169cNFq+X16XrQZV1+zp58iQ7duzA0dGRV1991aA3CjScpkJVNdLfgze3J3H6+j26eynzqFlXC7tv5eQT81MaW+NSSb2di3NTW55/tB2hfdvySKvy7/qglFlUczMZzLS0NNavX1+tnVbW7atdu3b6YayVlXSaH+LnzrwdyexOzFBkMGtjYbdh0O14OsCLq7dz+fZ0JoXFOvq2dyFiSGeGdnPHztb0KY6GyGQw3dzc2LhxI507/+8ypbJ+mRUJCAhg27ZtjBgxgqNHj/LMM8/ot7Vr146bN2/i4OBAcXFxJXtpHJybqRnQsSV7kzJ4c5jyhrNR+86Vu7D79ZhTrDtyBXu1Nfa21jRVW//msU25z8en3mHd4Sv6SZt0TR7vH7qEva0VYf3aMe533nR0k2WKJoPp7e1Ndna2wQXSpoL5YLevrl276rt9TZs2TX9v2ry8PMLDwx/+J2gARvbw4I3tiSSn36NHG2UdNStawF1UoqOlgxptYTGa3AKua4rRFhajLSgmt6DYKMymODdVs2CUnzlKbhBMdvsCLH6hdH3t9lVVmtwCApfsZ/LA9swd3tXS5QCQW1DEP749z8dHrpS73cvJnh/mPFHh63U6HXmFJeQWFBkENuRfP1DeL5wKuLIs2DzFNwByobQCODVV81inluxJzGDOsC4WH84evvALb+1I4tptLQM6uHAiVUNe4f/OF1bllIRKpSodwqoNPyN6OtmTXs5RuCGcezQnuVBaIYJ7eJB2R0ti2l2L1aDJLSDis1OErYvD1sqKbVP7sWVKf5Y944+Xkz0qSo+Ubz/To8YTP7OH+mL/mwmdhnLu0ZzkQmmFGOLnzpuqRMZ/fJz7+UV1ek5Op9OxJymDRV+dRpNbyCuDO/DqE530M6LmPCWhpCs4lMzkZ8yMjAzWrl1LamoqPj4+TJ482eQCA3Nr6J8xofQUwqzPEih54G/D3tb6oY5OVZFxV8v8ncnsP3sT/zaOLHvGHz9PWVRvaRUe/nQ6HSqVitatWxMZGan/WtSOqH3nDEIJ/7vfTG0Es6REx+a4VJZ/nUJRSQmRwV2ZNKAdNtZyblkJKgzmsmXLmDt3LhMnTtQHsiycmzZtqrMCG4uKTkuka7RsPn6VgR1b0da1qVne6+LNHOZ+kciPP9/hsY4tWfqHHmbbtzCPCoM5d+5cAKZNm6Zf9wrw008/1X5VjVBFs5VWKpi3IxmAti5NebRjSwZ2asmADq44NVVX6z0KikpY8/0l3jtwEXu1NVF/8udPvdvISEiBTM7kfPjhhwbB3LBhA4GBgbVaVGM0e6hvuVdKLP1Dd3q0ceKHi7c4fOEWu05dZ2tcKioV9PByLA1qx5b08nE2WL722/WtY/u0YW9S6d3ggv09WDSqG62aN7HEjyqqoMLJn+3bt7N9+3bOnz+Pr68vOp0OKysrevTowZtvvlmnRTaGyR+o2mLxwuISEtM0HL5wix8u3uJkqoaiEh12tlb0aefCwE4tKSgu4V8HL6ItNLxWsYWdNe8825On/FrX5Y8lasDkrOzBgwd54omKV3jUhcYSzJrIyS/i+OUsfVAv3Ky4nbyHox2xcxvmVToNjckpuP379+sf63Q65s2bV6sFiepxaGJDUNfWLBrdjf/MepxjlQQv867cSK2+MBnMa9eu6R+rVCpSU1NrtSDxcNwd7fCqYHmbLHurP0wG09nZmZiYGC5evEhMTAzOzs51UZd4CLLsrf4zGczly5dz//59PvnkE7RarbRIqAdCenrx9jM9zLa+VdS9Kl32VVBQQFZWVpXv+WNuMvkjGhuT5zHXrFnDkSNHuHz5Mm3btkWtVrNhw4Y6KE2IxsvkUPbAgQNs2rSJ9u3bs2XLFpycnOqiLiEaNZPBVKtLl33Z2dnx448/cunSpVovSojGzmQw582bR0FBAXPmzGHfvn288cYbdVGXEI1apcHU6XT8+9//Rq1W06FDByIjIxk4cGBd1SZEo1VpMFUqFa1ateLUqVMUFRVRUlJCSYlxrwghhHmZnJVNTEwkMTFR31G6qtdjVtRUCEp7bgYFBREVFWVw5YoQolSFwczJycHBwYHo6Ohq77SypkIAMTExBjeQFkIYqnAo+/LLL+sfv/XWW9XaaXlNhcoUFBSQkJBAr169qlurEI1GlW55l5aWVq2dVtZUaMeOHYwePZrExMRyX9uYun0JUZEKg5mWlsaqVavQ6XT6x2VmzJhR6U4raipUVFTEkSNHWL16dYXBbGzdvoQoT6U34ypT3QmaipoKZWVlcf36dSZPnkxqaiqHDh2iW7duODoqq1+HEJZWYTD79u1b451W1lRo+/btAKxevZrevXtLKIUoR5WuLrE0ubpENDZyd18hFEiCKYQCSTCFUCAJphAKJMEUQoEkmEIokARTCAWSYAqhQBJMIRRIgimEAkkwhVAgCaYQCiTBFEKBJJhCKJAEUwgFkmAKoUASTCEUSIIphAJJMIVQIAmmEAokwRRCgSSYQihQlVok1ERF3b4WLFjA+fPnUalULFy4kC5dutRWCULUW7USzMq6fU2ZMgVvb29+/vln3nnnHVavXm1yf8XFxQBkZmbWRrlC1Dp3d3dsbKoet1oJZnndvsqCWdZsyMbGBisr45F0eU2F7t+/D8D48eNro1whal11b1ZeK8GsrNtXmX/84x+EhYUZPV9eU6G8vDyefvpp1qxZg7W1dW2U/FBeeuklPvzwQ0uXUS6prWbMXZu7u3u1vr9WgllRt68yGzZsoEOHDgQGBlZpf3Z2djRr1gwfHx+z12oOarVasa0bpLaasXRttTIrGxAQwLFjxwA4evQoAQEB+m1Hjhzh5MmTBo1xhRCGaiWYD3b7sra21nf7Ali8eDFpaWlMmDCBBQsW1MbbC1Hv1drpkgdPkQBMmzYNgH379tXWWwrRYFgvWrRokaWLqKru3btbuoQKSW01I7WVr170xxSisZEleUIokARTCAWSYAqhQPUimEuXLmXcuHEsWbLE0qUYOHXqFM899xyhoaEsXbrU0uWUa8OGDYSGhlq6DCM7d+5k4sSJhIWFcePGDUuXo6fVapk6dSphYWFMmzaNgoICi9Sh+GA+uCC+sLCQxMRES5ek5+npycaNG9m6dStZWVmcO3fO0iUZKCgo4OzZs5Yuw8iNGzeIi4tj48aNREdH07p1a0uXpHf48GH8/f2Jjo7G39+f77//3iJ1KD6Y5S2IV4pWrVrRpEkTAGxtbRW3jjcmJoaQkBBLl2Hk8OHDlJSUMHHiRBYvXqy/ekgJ2rZti1arBeDevXs4OTlZpA7FBzM7OxsHBwegdA3uvXv3LFyRsZSUFG7fvk3Hjh0tXYpeYWEhcXFx9O/f39KlGMnKyqKwsJCNGzdiZ2fHgQMHLF2Sno+PDwkJCQQHB5OcnEyvXr0sUofig2lqQbylaTQaFi9ezN/+9jdLl2Lgyy+/ZNSoUZYuo1wODg706dMHgH79+nHp0iULV/Q/O3bsYPDgwezZs4dBgwbx1VdfWaQOxQezsgXxllZUVMTs2bN58803adWqlaXLMXDlyhW2bt3K5MmTuXjxItHR0ZYuSa9Xr176z+Nnz55V1BUmOp0OR0dHAJydncnOzrZIHfVi5c+SJUs4c+YMXbt2Zf78+ZYuR2/37t0sWbKETp06ATBr1ix69uxp4aqMhYaGsnXrVkuXYWD58uUkJyfj7OzMihUrUKvVli4JKP1c+dprr1FQUICNjQ3vvvuuRT5n1otgCtHYKH4oK0RjJMEUQoEkmEIokARTCAWSYAqhQBJMBTh+/Dg9e/bUr2qaM2cOV69erdG+vvjiC2JiYsxZHrm5uTz33HNMnz7d4PnPP/+8WvsJCwujqKjInKU1WBJMhfDw8DB7oKqqpKSk0u0pKSkEBgby3nvvGTy/ffv22iyrUau1m3GJ6gkKCuK7775j0qRJ+udWr15N7969GTBgAHPmzCE8PJy4uDgOHTpEXl4excXFPPHEE+zdu5d27drplwUePHiQb775BrVazapVq7C1tWXRokVcuXIFOzs7oqKiSElJYf369UDpAoTHH38cKF2b/Prrr5OTk0PXrl2JjIwkKiqKzMxMrK2tee2114DSO+afP3+esLAwIiMjiYmJISUlhZKSElasWEHLli0JDw9Hq9Xi4uLCqlWr9D/Xrl27SExM5JVXXuHVV18FwNfX1+gGbo2ZHDEVwsrKisGDB/Ptt9+a/F43NzfWrFmDp6cnhYWFbN68mYyMDDQaDQCurq6sW7eOnj178p///IfvvvsOT09PNm3axPjx4/n000+B0oXuH374oT6UUBq44cOHs3nzZrRaLadOnWLmzJmMHj1aH0oovWN+586diY6OxtfXl4iICD755BPCw8PZtm0bmZmZuLi4EB0dzcqVK/Wv2717N6dOnWLevHmcPXuWvn37Eh0dzbx588z1R9kgyBFTQcaMGcPMmTNxc3MDQKVS6bc9uECrc+fOQGlAy5YDurm56T+jdu3aVf//pKQkbG1t2bNnD0eOHKGoqEi/3rhbt25GNaSmpuqD2r17d65evVql6yU//vhjYmNjKSoqokOHDrRt25bOnTsTERFB9+7def755wFYu3YtW7ZsASAwMJC4uDgiIiIYOHCgIi9RsxQJpoK0aNGC9u3bExsbC5RehXHz5k10Op1B/5cHA1teeMsWiKekpNC2bVvs7OwICQnhhRdeAEqPlCdOnDB4bZm2bdty+vRpOnXqRHJyMmPGjCE/P7/cestef+fOHeLi4tiyZQs//PADu3btoqCggEmTJmFlZcULL7ygv9Jl2bJlzJ49m/feew+VSsWMGTMAePrppyWYD5ChrMKEhYVx+fJlAIYMGcKmTZuYMWOG/oqHqtBoNLzwwgvEx8czZMgQgoKCSE9PZ8KECUyYMKHSq/KfffZZ9uzZw7hx41Cr1ZVezePh4cGrr75KVlYWTZs2ZcKECRw6dAiA9PR0xo8fz9ixY3F2dsbV1RUoPYpPnjyZN954g8TEREJDQxkzZoz+YnhRShaxC6FAcsQUQoEkmEIokARTCAWSYAqhQBJMIRRIgimEAkkwhVCg/w/fwcOAPkMXwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(0,n_tasks), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0, n_tasks)\n",
    "ylim(0.2, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "print(mean_stuff)\n",
    "simple_axis(ax)\n",
    "gcf().tight_layout()\n",
    "plt.savefig('Normalcase_fractional_correct_NSLKDD.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Autocorrelation Matrix for task= 0 is : 29\n",
      "Rank of the Autocorrelation Matrix for task= 1 is : 18\n",
      "Rank of the Autocorrelation Matrix for task= 2 is : 24\n",
      "Rank of the Autocorrelation Matrix for task= 3 is : 21\n",
      "Rank of the Autocorrelation Matrix for task= 4 is : 15\n",
      "Rank of the Autocorrelation Matrix for task= 5 is : 22\n",
      "Rank of the Autocorrelation Matrix for task= 6 is : 21\n",
      "Rank of the Autocorrelation Matrix for task= 7 is : 16\n",
      "Rank of the Autocorrelation Matrix for task= 8 is : 29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import matrix_rank\n",
    "import math\n",
    "corr_matrix = []\n",
    "corr_row = []\n",
    "Rank_corr_matrix=[]\n",
    "for j in range(n_tasks):\n",
    "    df = pd.DataFrame(training_datasets[j][0])\n",
    "    correlation_matrix = df.corr().values\n",
    "    correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "    for k in range(len(correlation_matrix)):\n",
    "        for i in range(len(correlation_matrix)):\n",
    "            corr_elem = (math.ceil(correlation_matrix[k][i]*1e10)/1e10)\n",
    "            corr_row.append(np.around(corr_elem))\n",
    "        corr_matrix.append(corr_row)\n",
    "        corr_row = []\n",
    "    rank_corr_matrix=np.linalg.matrix_rank(np.asarray(corr_matrix))\n",
    "    Rank_corr_matrix.append(rank_corr_matrix)\n",
    "    print('Rank of the Autocorrelation Matrix for task=',j,'is :',rank_corr_matrix)\n",
    "    corr_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 90)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_weights_save),len(save_weights_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 510\n",
      "Rank of the Hessian Matrix after task= 1 is : 2693\n",
      "Rank of the Hessian Matrix after task= 2 is : 2942\n",
      "Rank of the Hessian Matrix after task= 3 is : 3175\n",
      "Rank of the Hessian Matrix after task= 4 is : 3238\n",
      "Rank of the Hessian Matrix after task= 5 is : 3279\n",
      "Rank of the Hessian Matrix after task= 6 is : 3330\n",
      "Rank of the Hessian Matrix after task= 7 is : 3392\n",
      "Rank of the Hessian Matrix after task= 8 is : 3472\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    if i == 0:\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-2])))\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-1])))\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(len(Flatten_weights)):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    if i == 2:\n",
    "        pass\n",
    "    else :\n",
    "        temp=list(np.asarray(Extract_model_params[i])-np.asarray(Extract_model_params[i-1]))\n",
    "        gradient = [j/0.001 for j in temp]\n",
    "        gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucledian Parameter shift after task 1 : 0.03723597654327982\n",
      "Eucledian Parameter shift after task 2 : 0.0\n",
      "Eucledian Parameter shift after task 3 : 2.2425232823171686\n",
      "Eucledian Parameter shift after task 4 : 1.2511803115675713\n",
      "Eucledian Parameter shift after task 5 : 1.0275412286612127\n",
      "Eucledian Parameter shift after task 6 : 0.836811011983417\n",
      "Eucledian Parameter shift after task 7 : 0.8247598133331262\n",
      "Eucledian Parameter shift after task 8 : 0.49098704763945256\n",
      "Cosine Parameter shift after task 1 : 1.0\n",
      "Cosine Parameter shift after task 2 : 1.0\n",
      "Cosine Parameter shift after task 3 : 0.943\n",
      "Cosine Parameter shift after task 4 : 0.983\n",
      "Cosine Parameter shift after task 5 : 0.989\n",
      "Cosine Parameter shift after task 6 : 0.992\n",
      "Cosine Parameter shift after task 7 : 0.993\n",
      "Cosine Parameter shift after task 8 : 0.997\n",
      "Jaccard Parameter shift after task 1 : 0.19658994032395566\n",
      "Jaccard Parameter shift after task 2 : 1.0\n",
      "Jaccard Parameter shift after task 3 : 0.13750600288138307\n",
      "Jaccard Parameter shift after task 4 : 0.14023816985271076\n",
      "Jaccard Parameter shift after task 5 : 0.13293741434444953\n",
      "Jaccard Parameter shift after task 6 : 0.25970149253731345\n",
      "Jaccard Parameter shift after task 7 : 0.22579113924050634\n",
      "Jaccard Parameter shift after task 8 : 0.2527367920038077\n",
      "Heuristic Parameter shift after task 1 : 0.26373626373626374\n",
      "Heuristic Parameter shift after task 2 : 1.0\n",
      "Heuristic Parameter shift after task 3 : 0.3525641025641026\n",
      "Heuristic Parameter shift after task 4 : 0.3608058608058608\n",
      "Heuristic Parameter shift after task 5 : 0.33791208791208793\n",
      "Heuristic Parameter shift after task 6 : 0.4793956043956044\n",
      "Heuristic Parameter shift after task 7 : 0.42857142857142855\n",
      "Heuristic Parameter shift after task 8 : 0.4500915750915751\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "from math import*\n",
    "#1. Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "#2. Manhattan Distance\n",
    "def manhattan_distance(x,y):\n",
    "    return sum(abs(a-b) for a,b in zip(x,y))\n",
    "#3.  Minkowski distance \n",
    "from decimal import Decimal\n",
    "def nth_root(value, n_root):\n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def minkowski_distance(x,y,p_value):\n",
    "    return nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),p_value)\n",
    "#4. Cosine Similarity\n",
    "def square_rooted(x):\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "#5. Jaccard similarity\n",
    "def jaccard_similarity(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "#6. Using Heuristic    \n",
    "import difflib \n",
    "\n",
    "for i in [0,1,2,3,4,5,6,7]:\n",
    "    print(\"Eucledian Parameter shift after task {0} :\".format(i+1),euclidean_distance(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7]:\n",
    "    print(\"Cosine Parameter shift after task {0} :\".format(i+1),cosine_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7]:\n",
    "    print(\"Jaccard Parameter shift after task {0} :\".format(i+1),jaccard_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7]:\n",
    "    print(\"Heuristic Parameter shift after task {0} :\".format(i+1),difflib.SequenceMatcher(None,Extract_model_params[i],Extract_model_params[i+1]).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of changed parameters\n",
    "changed_model_parameters=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    temp=[]\n",
    "    for j,k in zip(Extract_model_params[i],Extract_model_params[i-1]):\n",
    "        temp.append(abs(i-j))\n",
    "    changed_model_parameters.append(temp)\n",
    "print(len(changed_model_parameters))\n",
    "\n",
    "import csv\n",
    "#Save the model parameters in text file\n",
    "with open('temp', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(Extract_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----After learning 2 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 3 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 4 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 5 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 6 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 7 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 8 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 9 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 10 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 11 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n"
     ]
    }
   ],
   "source": [
    "#Number of parameters unchanged within the thresold. Checked for five threshold values as [1e-5, 1e-4, 1e-3, 1e-2, 1e-1].\n",
    "for i in range(len(changed_model_parameters)):\n",
    "    print('-----After learning',i+2,'task-----')\n",
    "    for j in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "        print(j,'---->',sum(k < j for k in changed_model_parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
